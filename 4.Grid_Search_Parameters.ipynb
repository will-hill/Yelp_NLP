{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search all Parameters and HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Entire Dataset\n",
    "51 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_all\t \n",
      "CPU times: user 48.1 s, sys: 7.09 s, total: 55.2 s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# REVIEW_FILE_CSV = 'reviews.csv'\n",
    "SHUFFLED_REVIEW_FILE_CSV = 'shuffled.reviews.csv'\n",
    "import pandas as pd\n",
    "df_all = pd.read_csv(SHUFFLED_REVIEW_FILE_CSV)\n",
    "del pd, SHUFFLED_REVIEW_FILE_CSV\n",
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(size, metric):\n",
    "    return df_all[[metric, 'text']].head(size)\n",
    "\n",
    "def data_prep(df, metric):\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(df.text.values)\n",
    "    VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "\n",
    "    X = tokenizer.texts_to_sequences(df.text.values)\n",
    "    X = pad_sequences(X)\n",
    "    # Normalize Y to be between 0 and 1\n",
    "    Y = df[metric] / max(df[metric])\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "    return X, Y, VOCAB_SIZE, X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterized Neural Net Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_factory(X_train, VOCAB_SIZE, EMBED_OUTPUT_DIM, LSTM_OUT, LSTM_DROPOUT, RECURRENT_DROPOUT, USE_SPATIAL_DROPOUT, SPATIAL_DROPOUT):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO https://realpython.com/python-keras-text-classification/\n",
    "\n",
    "    # https://keras.io/layers/embeddings/\n",
    "    # keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "    model.add(Embedding(VOCAB_SIZE,\n",
    "                        EMBED_OUTPUT_DIM,\n",
    "                        mask_zero=True,\n",
    "                        input_length=X_train.shape[1]))\n",
    "\n",
    "    if USE_SPATIAL_DROPOUT:\n",
    "        model.add(SpatialDropout1D(SPATIAL_DROPOUT))\n",
    "\n",
    "    if LSTM_LAYER_COUNT > 1:\n",
    "        for i in range(LSTM_LAYER_COUNT):\n",
    "            model.add(LSTM(LSTM_OUT, return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=RECURRENT_DROPOUT))\n",
    "\n",
    "    model.add(LSTM(LSTM_OUT, dropout=LSTM_DROPOUT, recurrent_dropout=RECURRENT_DROPOUT))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### induce and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, model_name, X_train, Y_train, EPOCHS, BATCH_SIZE):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(history.history['acc'], '.-')\n",
    "    plt.plot(history.history['val_acc'], '.-')\n",
    "    plt.plot(history.history['loss'], '.-')\n",
    "    plt.plot(history.history['val_loss'], '.-')\n",
    "\n",
    "    plt.title('training')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['acc', 'val_acc', 'loss', 'val_loss'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    loss, mae, acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=BATCH_SIZE)\n",
    "    print('loss(mse):' + str(loss))  # mse\n",
    "    print('mae:' + str(mae))\n",
    "    print('acc:' + str(acc))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    #y_pred[0:5]\n",
    "    #Y_test[0:5]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(Y_test, y_pred)\n",
    "    ax.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    return loss, mae, acc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and Hyperparameters to Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = 20\n",
    "METRIC = 'stars'  # ['stars','funny'] # 'useful' ,'cool']\n",
    "\n",
    "EMBED_OUTPUT_DIM = 8  # 128\n",
    "\n",
    "USE_SPATIAL_DROPOUT = False\n",
    "SPATIAL_DROPOUT = 0.1\n",
    "\n",
    "LSTM_LAYER_COUNT = 1\n",
    "LSTM_OUT = 8  # 196\n",
    "LSTM_DROPOUT = 0.1\n",
    "RECURRENT_DROPOUT = 0.1\n",
    "\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 259, 8)            5968      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 6,521\n",
      "Trainable params: 6,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Variable              Type          Data/Info\n",
      "---------------------------------------------\n",
      "DATA_SIZE             int           20\n",
      "EMBED_OUTPUT_DIM      int           8\n",
      "EPOCHS                int           1\n",
      "LSTM_DROPOUT          float         0.1\n",
      "LSTM_LAYER_COUNT      int           1\n",
      "LSTM_OUT              int           8\n",
      "METRIC                str           stars\n",
      "RECURRENT_DROPOUT     float         0.1\n",
      "SPATIAL_DROPOUT       float         0.1\n",
      "USE_SPATIAL_DROPOUT   bool          False\n",
      "VOCAB_SIZE            int           746\n",
      "X                     ndarray       20x259: 5180 elems, type `int32`, 20720 bytes\n",
      "X_test                ndarray       7x259: 1813 elems, type `int32`, 7252 bytes\n",
      "X_train               ndarray       13x259: 3367 elems, type `int32`, 13468 bytes\n",
      "Y                     Series        0     1.0\\n1     0.8\\n2  <...>me: stars, dtype: float64\n",
      "Y_test                Series        0     1.0\\n17    0.6\\n15 <...>me: stars, dtype: float64\n",
      "Y_train               Series        3     1.0\\n18    0.4\\n16 <...>me: stars, dtype: float64\n",
      "data_prep             function      <function data_prep at 0x7f5843ee8400>\n",
      "df                    DataFrame         stars                <...> for 2 years after hea...\n",
      "df_all                DataFrame              Unnamed: 0      <...>685902 rows x 10 columns]\n",
      "get_data              function      <function get_data at 0x7f5843ee8488>\n",
      "model                 Sequential    <keras.engine.sequential.<...>object at 0x7f593030c470>\n",
      "model_factory         function      <function model_factory at 0x7f5843ee8378>\n",
      "CPU times: user 1.07 s, sys: 545 ms, total: 1.61 s\n",
      "Wall time: 1.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "df = get_data(DATA_SIZE, METRIC)\n",
    "X, Y, VOCAB_SIZE, X_train, X_test, Y_train, Y_test = data_prep(df, METRIC)\n",
    "\n",
    "model = model_factory(X_train, VOCAB_SIZE, EMBED_OUTPUT_DIM, LSTM_OUT, LSTM_DROPOUT, RECURRENT_DROPOUT, USE_SPATIAL_DROPOUT, SPATIAL_DROPOUT)\n",
    "print(model.summary())\n",
    "\n",
    "model_name = METRIC + '_epochs-' + str(EPOCHS) + '_batch_sz-' + str(BATCH_SIZE) + '_data_sz-' + str(DATA_SIZE)\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, Y_train, validation_split=0.333, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2)\n",
    "fit_time = time.time() - start_time\n",
    "\n",
    "loss, mae, acc = evaluate_model(model, model_name, X_train, Y_train, EPOCHS, BATCH_SIZE)\n",
    "\n",
    "model.save(model_name + '.' + str(fit_time) + '_loss-' +  str(loss) + '_mae-' + str(mae) + '_acc=' + str(acc) + '.h5')\n",
    "\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

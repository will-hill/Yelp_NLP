{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimized HyperParameters \n",
    "## AutoML applied to NLP - DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28 seconds loading CSV into memory\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# REVIEW_FILE_CSV = 'reviews.csv'\n",
    "SHUFFLED_REVIEW_FILE_CSV = 'shuffled.100000.reviews.csv'  # 'shuffled.reviews.csv'\n",
    "import pandas as pd\n",
    "\n",
    "# GLOBAL VAR df_all <-- all review data\n",
    "start = time.time()\n",
    "df_all = pd.read_csv(SHUFFLED_REVIEW_FILE_CSV)\n",
    "csv_load_time = time.time() - start\n",
    "print(str(round(csv_load_time, 2)) + ' seconds loading CSV into memory')\n",
    "del pd, SHUFFLED_REVIEW_FILE_CSV, start, csv_load_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(size, metric):\n",
    "    return df_all[[metric, 'text']].head(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df, metric):\n",
    "    from keras.preprocessing.text import Tokenizer\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(df.text.values)\n",
    "    VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "\n",
    "    X = tokenizer.texts_to_sequences(df.text.values)\n",
    "    X = pad_sequences(X)\n",
    "    # Normalize Y to be between 0 and 1\n",
    "    Y = df[metric] / max(df[metric])\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "    return X, Y, VOCAB_SIZE, X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Factory\n",
    "https://en.wikipedia.org/wiki/Factory_method_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_factory(X_train, VOCAB_SIZE, EMBED_OUTPUT_DIM, LSTM_LAYER_COUNT, LSTM_OUT, LSTM_DROPOUT, RECURRENT_DROPOUT, USE_SPATIAL_DROPOUT, SPATIAL_DROPOUT,\n",
    "                  LEARNING_RATE):\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # TODO https://realpython.com/python-keras-text-classification/\n",
    "\n",
    "    # https://keras.io/layers/embeddings/\n",
    "    # keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "    model.add(Embedding(VOCAB_SIZE,\n",
    "                        EMBED_OUTPUT_DIM,\n",
    "                        mask_zero=True,\n",
    "                        input_length=X_train.shape[1]))\n",
    "\n",
    "    if USE_SPATIAL_DROPOUT:\n",
    "        model.add(SpatialDropout1D(SPATIAL_DROPOUT))\n",
    "\n",
    "    if LSTM_LAYER_COUNT > 1:\n",
    "        for i in range(LSTM_LAYER_COUNT):\n",
    "            model.add(LSTM(LSTM_OUT, return_sequences=True, dropout=LSTM_DROPOUT, recurrent_dropout=RECURRENT_DROPOUT))\n",
    "\n",
    "    model.add(LSTM(LSTM_OUT, dropout=LSTM_DROPOUT, recurrent_dropout=RECURRENT_DROPOUT))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    adam = keras.optimizers.Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer=adam, loss='mean_squared_error', metrics=['mae', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, history, X_test, Y_test, BATCH_SIZE):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(history.history['acc'], '.-')\n",
    "    plt.plot(history.history['val_acc'], '.-')\n",
    "    plt.plot(history.history['loss'], '.-')\n",
    "    plt.plot(history.history['val_loss'], '.-')\n",
    "\n",
    "    plt.title('training')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['acc', 'val_acc', 'loss', 'val_loss'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    loss, mae, acc = model.evaluate(X_test, Y_test, verbose=2, batch_size=BATCH_SIZE)\n",
    "    print('loss(mse):' + str(loss))  # mse\n",
    "    print('mae:' + str(mae))\n",
    "    print('acc:' + str(acc))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    # y_pred[0:5]\n",
    "    # Y_test[0:5]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(Y_test, y_pred)\n",
    "    ax.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "    return loss, mae, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterized Experiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(DATA_SIZE,\n",
    "                   METRIC,\n",
    "                   EMBED_OUTPUT_DIM,\n",
    "                   LSTM_LAYER_COUNT,\n",
    "                   LSTM_OUT,\n",
    "                   LSTM_DROPOUT,\n",
    "                   RECURRENT_DROPOUT,\n",
    "                   USE_SPATIAL_DROPOUT,\n",
    "                   SPATIAL_DROPOUT,\n",
    "                   EPOCH,\n",
    "                   BATCH_SIZE,\n",
    "                   LEARNING_RATE):\n",
    "    import uuid\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    import numpy as np\n",
    "\n",
    "    DATA_SIZE = int(round(DATA_SIZE))\n",
    "    metric_dict = {0: 'stars', 1: 'funny', 2: 'useful', 3: 'cool'}\n",
    "    METRIC = metric_dict[round(METRIC, 0)]\n",
    "    EMBED_OUTPUT_DIM = int(round(EMBED_OUTPUT_DIM))\n",
    "    LSTM_LAYER_COUNT = int(round(LSTM_LAYER_COUNT))\n",
    "    LSTM_OUT = int(round(LSTM_OUT))\n",
    "    USE_SPATIAL_DROPOUT = bool(int(round(USE_SPATIAL_DROPOUT)))\n",
    "    EPOCH = int(round(EPOCH))\n",
    "    BATCH_SIZE = int(round(BATCH_SIZE))\n",
    "\n",
    "    df = get_data(DATA_SIZE, METRIC)\n",
    "    X, Y, VOCAB_SIZE, X_train, X_test, Y_train, Y_test = data_prep(df, METRIC)\n",
    "\n",
    "    model = model_factory(X_train, VOCAB_SIZE, EMBED_OUTPUT_DIM, LSTM_LAYER_COUNT, LSTM_OUT, LSTM_DROPOUT, RECURRENT_DROPOUT, USE_SPATIAL_DROPOUT,\n",
    "                          SPATIAL_DROPOUT, LEARNING_RATE)\n",
    "    print(model.summary())\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, Y_train, validation_split=0.333, epochs=EPOCH, batch_size=BATCH_SIZE, verbose=2)\n",
    "    fit_time = time.time() - start_time\n",
    "\n",
    "    loss, mae, acc = evaluate_model(model, history, X_test, Y_test, BATCH_SIZE)\n",
    "\n",
    "    results_dict = {}\n",
    "    results_dict['EMBED_OUTPUT_DIM'] = EMBED_OUTPUT_DIM\n",
    "    results_dict['USE_SPATIAL_DROPOUT'] = USE_SPATIAL_DROPOUT\n",
    "    results_dict['SPATIAL_DROPOUT'] = SPATIAL_DROPOUT\n",
    "    results_dict['LSTM_LAYER_COUNT'] = LSTM_LAYER_COUNT\n",
    "    results_dict['LSTM_OUT'] = LSTM_OUT\n",
    "    results_dict['LSTM_DROPOUT'] = LSTM_DROPOUT\n",
    "    results_dict['RECURRENT_DROPOUT'] = RECURRENT_DROPOUT\n",
    "    results_dict['BATCH_SIZE'] = BATCH_SIZE\n",
    "    results_dict['LEARNING_RATE'] = LEARNING_RATE\n",
    "    results_dict['EPOCH'] = EPOCH\n",
    "    results_dict['DATA_SIZE'] = DATA_SIZE\n",
    "    results_dict['METRIC'] = METRIC\n",
    "\n",
    "    results_dict['loss'] = loss\n",
    "    results_dict['mae'] = mae\n",
    "    results_dict['acc'] = acc\n",
    "    results_dict['fit_time'] = fit_time\n",
    "\n",
    "    model_uuid = uuid.uuid4().hex\n",
    "    results_dict['model_uuid'] = model_uuid\n",
    "\n",
    "    results_dict['timestamp'] = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "\n",
    "    model.save('./models/' + model_uuid + '.h5')\n",
    "\n",
    "    # metric for Baysean Optimization\n",
    "    # thing to minimize:\n",
    "    # Mean of\n",
    "    #   loss\n",
    "    #   1.00-accuracy\n",
    "    #   secs_to_run / 600 seconds\n",
    "    bayes_metric = np.mean(np.array([1 - loss, 1 - mae, acc * 100, 600 - fit_time]))\n",
    "    results_dict['bayes_metric'] = bayes_metric\n",
    "\n",
    "    results_df = pd.DataFrame.from_dict([results_dict], orient='columns')\n",
    "    with open('results.csv', 'a') as f:\n",
    "        results_df.to_csv(f, header=False)\n",
    "\n",
    "    return bayes_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization\n",
    "https://pypi.org/project/bayesian-optimization/  \n",
    "https://github.com/fmfn/BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baysean_param_search():\n",
    "    from bayes_opt import BayesianOptimization\n",
    "    from functools import partial\n",
    "\n",
    "    pbounds = {\n",
    "        'DATA_SIZE': (10000.0, 10000.1),\n",
    "        'METRIC': (0, 3),\n",
    "        'EMBED_OUTPUT_DIM': (8, 512),\n",
    "        'USE_SPATIAL_DROPOUT': (0, 1),\n",
    "        'SPATIAL_DROPOUT': (0.0, 0.1),\n",
    "        'LSTM_LAYER_COUNT': (0, 2),\n",
    "        'LSTM_OUT': (4, 256),\n",
    "        'LSTM_DROPOUT': (0.0, 0.33),\n",
    "        'RECURRENT_DROPOUT': (0.0, 0.33),\n",
    "        'EPOCH': (3, 6),\n",
    "        'BATCH_SIZE': (4, 256),\n",
    "        'LEARNING_RATE': (0.0001, 0.5)\n",
    "    }\n",
    "\n",
    "    import numpy as np\n",
    "    _bounds = np.array([item[1] for item in sorted(pbounds.items(), key=lambda x: x[0])], dtype=np.float)\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=run_experiment,\n",
    "        pbounds=pbounds,\n",
    "        verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "        random_state=1,\n",
    "    )\n",
    "\n",
    "    optimizer.maximize(init_points=10, n_iter=1000, )\n",
    "\n",
    "    for i, res in enumerate(optimizer.res):\n",
    "        print(\"Iteration {}: \\n\\t{}\".format(i, res))\n",
    "\n",
    "    print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | BATCH_... | DATA_SIZE | EMBED_... |   EPOCH   | LEARNI... | LSTM_D... | LSTM_L... | LSTM_OUT  |  METRIC   | RECURR... | SPATIA... | USE_SP... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 22:03:02.847035 140508224075584 deprecation_wrapper.py:119] From /home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0804 22:03:02.862495 140508224075584 deprecation_wrapper.py:119] From /home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0804 22:03:02.865391 140508224075584 deprecation_wrapper.py:119] From /home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0804 22:03:02.883525 140508224075584 deprecation_wrapper.py:119] From /home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0804 22:03:02.892077 140508224075584 deprecation.py:506] From /home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0804 22:03:03.305063 140508224075584 deprecation.py:323] From /home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0804 22:03:03.435084 140508224075584 deprecation_wrapper.py:119] From /home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 966, 8)            234264    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 966, 8)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 91)                36400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 92        \n",
      "=================================================================\n",
      "Total params: 270,756\n",
      "Trainable params: 270,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0804 22:03:04.207628 140508224075584 deprecation_wrapper.py:119] From /home/will/anaconda3/envs/Yelp_NLP/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4468 samples, validate on 2232 samples\n",
      "Epoch 1/4\n",
      " - 107s - loss: 0.1483 - mean_absolute_error: 0.2766 - acc: 0.6744 - val_loss: 0.0040 - val_mean_absolute_error: 0.0493 - val_acc: 0.8006\n",
      "Epoch 2/4\n",
      " - 103s - loss: 0.0071 - mean_absolute_error: 0.0624 - acc: 0.7912 - val_loss: 0.0038 - val_mean_absolute_error: 0.0589 - val_acc: 0.8006\n",
      "Epoch 3/4\n",
      " - 103s - loss: 0.0031 - mean_absolute_error: 0.0339 - acc: 0.7912 - val_loss: 0.0014 - val_mean_absolute_error: 0.0278 - val_acc: 0.8006\n",
      "Epoch 4/4\n"
     ]
    }
   ],
   "source": [
    "baysean_param_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

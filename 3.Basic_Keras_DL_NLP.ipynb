{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/will-hill/Yelp_NLP/blob/master/3.Basic_Keras_DL_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69lloxhH4GbP"
   },
   "source": [
    "# Basic Keras Deep Learning NLP\n",
    "inspired from \n",
    "* https://www.kaggle.com/ngyptr/lstm-sentiment-analysis-keras\n",
    "* https://medium.com/datadriveninvestor/building-neural-network-using-keras-for-regression-ceee5a9eadff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review File\n",
    "* 534,7475,638 bytes\n",
    "* 6,685,900 reviews/lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "c88Rto5fPt8X",
    "outputId": "0e84bbf4-b56f-4333-f5d9-7a00492b7149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:            125           6          78           0          40         117\n",
      "Swap:             7           0           7\n",
      "Sun Aug  4 15:20:15 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    30W / 250W |      0MiB / 16130MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nproc\n",
    "!free -g\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klkILKLwM8Yp"
   },
   "source": [
    "### Will's Setup Code\n",
    "I created a couple subdirectories in my Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAB\n",
    "REVIEW_FILE_JSON = 'review.json' \n",
    "# COLAB\n",
    "# REVIEW_FILE_JSON = '/content/drive/My Drive/colab/yelp_nlp/review.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Ar6urKZwM7mo",
    "outputId": "7e40e3b6-a25d-43c6-984b-ec428c93d0fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "9esZJkDhOCuR",
    "outputId": "22dba335-489f-422d-dfd4-3736eba5296c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW_FILE\t df\t \n",
      "CPU times: user 1min 10s, sys: 12.6 s, total: 1min 23s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "REVIEWS_TO_INGEST = 6685900\n",
    "data_list = list()\n",
    "columns = ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']\n",
    "\n",
    "# inspired by https://thedatafrog.com/text-mining-pandas-yelp/\n",
    "with open(REVIEW_FILE) as reviews:\n",
    "    import json\n",
    "    for i, line in enumerate(reviews):\n",
    "\n",
    "        if i == REVIEWS_TO_INGEST:\n",
    "            break\n",
    "\n",
    "            # convert json line to di t\n",
    "        data = json.loads(line)\n",
    "        data_list.append([data['review_id'],\n",
    "                          data['user_id'],\n",
    "                          data['business_id'],\n",
    "                          data['stars'],\n",
    "                          data['useful'],\n",
    "                          data['funny'],\n",
    "                          data['cool'],\n",
    "                          data['text'],\n",
    "                          data['date']])\n",
    "\n",
    "reviews.close()\n",
    "del reviews, i, line, data, REVIEWS_TO_INGEST, json\n",
    "###\n",
    "import pandas\n",
    "df = pandas.DataFrame(data_list, columns=columns)\n",
    "del data_list, columns, pandas\n",
    "\n",
    "%who"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 minutes, 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "p4ZmkBI_VqPG",
    "outputId": "2b0697af-acf5-4629-ae9a-e31dcacf3bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 5.84 s, total: 1min 41s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "# LAB   ~ 1:41\n",
    "%time df.to_csv('reviews.csv', index=False, encoding='UTF-8')\n",
    "# COLAB ~ 2:08 \n",
    "# %time df.to_csv('/content/drive/My Drive/colab/yelp_nlp/reviews.csv', index=False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BhZdfBb3VDST"
   },
   "outputs": [],
   "source": [
    "# LAB\n",
    "df.to_hdf('reviews.h5', key='df', mode='w')\n",
    "# COLAB\n",
    "# df.to_hdf('/content/drive/My Drive/colab/yelp_nlp/reviews.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nB6pmZ465PnJ"
   },
   "source": [
    "### Joanna Setup Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "uxeRqXUTgpxF",
    "outputId": "92ce5959-9f0b-47e8-b56d-0dfd75084e14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "data  drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive #python code\n",
    "drive.mount('/content/drive') # python code <- follow the resulting directions\n",
    "!ln -s drive/My\\ Drive data # bash command\n",
    "!ls # you should \"see\" drive directory now.\n",
    "hd5_path='data/reviews.h5'\n",
    "#!pip install numpy==1.15.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEBdJahR5hgq"
   },
   "source": [
    "## Regression: Number of Stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "GQ-iWw09bA74",
    "outputId": "9b2a0c7e-4f74-4673-86c6-6f07b048fa0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.3 s, sys: 6.39 s, total: 52.6 s\n",
      "Wall time: 48.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "REVIEW_FILE_CSV = 'reviews.csv'\n",
    "import pandas as pd\n",
    "df = pd.read_csv(REVIEW_FILE_CSV)\n",
    "del pd, REVIEW_FILE_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all.head(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['text'].values)\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "del Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(df.text.values)\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add zeroes so all texts are same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X)\n",
    "del pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Y to be between 0 and 1\n",
    "Y = df.stars / max(df.stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670000, 1047) (670000,)\n",
      "(330000, 1047) (330000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)\n",
    "\n",
    "del train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "Yz-gTcdOmqm_",
    "outputId": "6397910c-9a4d-40e0-e150-df412d71dd7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1047, 8)           2186320   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,186,873\n",
      "Trainable params: 2,186,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "\n",
    "OUTPUT_DIM = 8 #128\n",
    "LSTM_OUT = 8 #196\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# TODO https://realpython.com/python-keras-text-classification/\n",
    "\n",
    "\n",
    "# https://keras.io/layers/embeddings/\n",
    "# keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "model.add(Embedding(VOCAB_SIZE, \n",
    "                    OUTPUT_DIM, \n",
    "                    mask_zero=True,\n",
    "                    input_length = X_train.shape[1]))\n",
    "\n",
    "# model.add(SpatialDropout1D(0.2))\n",
    "\n",
    "# model.add(LSTM(LSTM_OUT, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(LSTM(LSTM_OUT, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(LSTM(LSTM_OUT, \n",
    "               dropout=0.0, \n",
    "               recurrent_dropout=0.0)\n",
    "         )\n",
    "\n",
    "\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "1000 reviews  \n",
    "1 epoch = 50 seconds  \n",
    "5 epochs = 2:55\n",
    "\n",
    "---\n",
    "50000 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7gC2Vwgstfan",
    "outputId": "b6e28266-6acb-42d8-880a-a6e3f8406c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 446890 samples, validate on 223110 samples\n",
      "Epoch 1/10\n",
      " - 3734s - loss: 0.0459 - mean_absolute_error: 0.1572 - acc: 0.4267 - val_loss: 0.0242 - val_mean_absolute_error: 0.1169 - val_acc: 0.4372\n",
      "Epoch 2/10\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "history = model.fit(X_train, Y_train, validation_split=0.333, epochs = epochs, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'], '.-')\n",
    "plt.plot(history.history['val_acc'], '.-')\n",
    "plt.plot(history.history['loss'], '.-')\n",
    "plt.plot(history.history['val_loss'], '.-')\n",
    "\n",
    "plt.title('training')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['acc','val_acc','loss','val_loss'], loc='best')\n",
    "\n",
    "del plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jrydM4PBtj8G"
   },
   "outputs": [],
   "source": [
    "loss, mae, acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "KaiYU61jw0zj",
    "outputId": "60f62f62-4445-415a-b112-382872d1a642"
   },
   "outputs": [],
   "source": [
    "print(loss) #mse\n",
    "print(mae)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhlxZi_StscF"
   },
   "outputs": [],
   "source": [
    "y_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "fTmU_8kStwHt",
    "outputId": "9844ac47-72b9-4519-c75c-df62630ddce7"
   },
   "outputs": [],
   "source": [
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "fzJ1euyzxUtZ",
    "outputId": "37e94f00-7c7b-4900-f334-316c895dceec"
   },
   "outputs": [],
   "source": [
    "Y_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "3IreN0qJ6LfO",
    "outputId": "89b4cd6f-2b59-4823-cb03-7906e127b3cb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y_test, y_pred)\n",
    "ax.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Final Project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
